### Project Files Overview

Below is a description of each file:

- **`parse_categorywise_entity_annotations.ipynb`**:  
  Parses all entities in the dataset and categorizes them as *included*, *excluded*, *seals*, *landscape*, or *ignored* based on the category-wise annotations performed earlier.  
  > _Note: WTQ uses a different file for the annotations._

- **`seals_collage_fetch.py`**:  
  Fetches collages of locations and seals corresponding to links created in the previous steps. This script saves the respective images and their paths based on the seal/location links.

- **`general_remove_rejected.py`**:  
  Removes the image tags of entities deemed irrelevant. These image IDs include those from rejected entities or collages that couldn't be generated.

- **`questionExtraction.ipynb`**:  
  Responsible for generating both explicit and implicit questions.

- **`create_experiment_ready_dataset.py`**:  
  Prunes the content of images in table columns to ensure they meet the dataset's criteria, reducing content to between 30% and 75%.

- **`fixing_explicit_questions.ipynb`**:  
  Adds extra information to explicit image data files to enhance their quality.

- **`download_all_tables.py`**:  
  Downloads all tables from HTML pages.

- **`links_to_image_pipeline.py`**:  
  Creates links from Wikipedia infobox pages to their corresponding images.

- **`segregate.py`**:  
  Segregates images based on the category of the entity, specifically focusing on seals.

- **`exact_match.py`**:  
  Implements the exact match evaluation metric for the dataset.

- **`create_train_test_split.py`**:  
  Generates the train-test split of the dataset.

- **`download_images.py`**:  
  Downloads images from links generated by `links_to_image_pipeline.py`.

- **`get_page_statistics.py`**:  
  Fetches view statistics for Wikipedia pages related to the dataset.

- **`visual_qs_gen_pipeline.ipynb`**:  
  Generates visual questions for the dataset. 