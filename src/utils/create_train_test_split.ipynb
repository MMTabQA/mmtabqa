{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "BASE_DIR = \"/home/suyash/final_repo/fetaqa_MM_cleaned\"\n",
    "\n",
    " \n",
    "visual_questions = []\n",
    "with open(os.path.join(BASE_DIR, \"experiment_ready_dataset\", \"visual_questions.jsonl\")) as f:\n",
    "    for line in f.readlines():\n",
    "        visual_questions.append(json.loads(line))\n",
    "    \n",
    "\n",
    "explicit_questions = []\n",
    "with open(os.path.join(BASE_DIR, \"experiment_ready_dataset\", \"explicit_questions.jsonl\")) as f:\n",
    "    for line in f.readlines():\n",
    "        explicit_questions.append(json.loads(line))\n",
    "\n",
    "implicit_questions = []\n",
    "\n",
    "with open(os.path.join(BASE_DIR, \"experiment_ready_dataset\", \"implicit_questions.jsonl\")) as f:\n",
    "    for line in f.readlines():\n",
    "        implicit_questions.append(json.loads(line))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(explicit_questions), len(implicit_questions), len(answer_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.shuffle(explicit_questions)\n",
    "# random.shuffle(implicit_questions)\n",
    "# random.shuffle(answer_questions)\n",
    "\n",
    "# train_explicit_questions = explicit_questions[:int(0.8*len(explicit_questions))]\n",
    "# train_implicit_questions = implicit_questions[:int(0.8*len(implicit_questions))]\n",
    "# train_answer_questions = answer_questions[:int(0.8*len(answer_questions))]\n",
    "\n",
    "train_visual_questions = visual_questions[:int(0.8*len(visual_questions))]\n",
    "test_visual_questions = visual_questions[int(0.8*len(visual_questions)):]\n",
    "\n",
    "\n",
    "# test_explicit_questions = explicit_questions[int(0.8*len(explicit_questions)):]\n",
    "# test_implicit_questions = implicit_questions[int(0.8*len(implicit_questions)):]\n",
    "# test_answer_questions = answer_questions[int(0.8*len(answer_questions)):]\n",
    "\n",
    "# train_tables = [ques['table_context'] for ques in train_explicit_questions]\n",
    "# train_tables = train_tables + [ques['table_context'] for ques in train_implicit_questions]\n",
    "# train_tables = train_tables + [ques['table_context'] for ques in train_answer_questions]\n",
    "\n",
    "# test_tables = [ques['table_context'] for ques in test_explicit_questions]\n",
    "# test_tables = test_tables + [ques['table_context'] for ques in test_implicit_questions]\n",
    "# test_tables = test_tables + [ques['table_context'] for ques in test_answer_questions]\n",
    "\n",
    "# train_exclusive_tables = list(set(train_tables) - set(test_tables))\n",
    "# test_exclusive_tables = list(set(test_tables) - set(train_tables))\n",
    "# common_tables = list(set(train_tables) & set(test_tables))\n",
    "\n",
    "# TABLES_SPLIT = {\n",
    "#     \"train\": train_exclusive_tables,\n",
    "#     \"test\": test_exclusive_tables,\n",
    "#     \"common\": common_tables\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_BASE_DIR = \"/home/suyash/final_repo/[temp]train_test_questions/\" + BASE_DIR.split(\"/\")[-1]\n",
    "\n",
    "# with open(os.path.join(NEW_BASE_DIR,  \"tables_split.json\"), \"w\") as f:\n",
    "#     json.dump(TABLES_SPLIT, f, indent=4)\n",
    "# with open(os.path.join(NEW_BASE_DIR,  \"train_explicit_questions.jsonl\"), \"w\") as f:\n",
    "#     for ques in train_explicit_questions:\n",
    "#         f.write(json.dumps(ques) + \"\\n\")\n",
    "# with open(os.path.join(NEW_BASE_DIR,  \"train_implicit_questions.jsonl\"), \"w\") as f:\n",
    "#     for ques in train_implicit_questions:\n",
    "#         f.write(json.dumps(ques) + \"\\n\")\n",
    "# with open(os.path.join(NEW_BASE_DIR,  \"train_answer_questions.jsonl\"), \"w\") as f:\n",
    "#     for ques in train_answer_questions:\n",
    "#         f.write(json.dumps(ques) + \"\\n\")\n",
    "\n",
    "\n",
    "# with open(os.path.join(NEW_BASE_DIR,  \"test_answer_questions.jsonl\"), \"w\") as f:\n",
    "#     for ques in test_answer_questions:\n",
    "#         f.write(json.dumps(ques) + \"\\n\")\n",
    "# with open(os.path.join(NEW_BASE_DIR,  \"test_explicit_questions.jsonl\"), \"w\") as f:\n",
    "#     for ques in test_explicit_questions:\n",
    "#         f.write(json.dumps(ques) + \"\\n\")\n",
    "# with open(os.path.join(NEW_BASE_DIR,  \"test_implicit_questions.jsonl\"), \"w\") as f:\n",
    "#     for ques in test_implicit_questions:\n",
    "#         f.write(json.dumps(ques) + \"\\n\")\n",
    "\n",
    "with open(os.path.join(NEW_BASE_DIR,  \"train_visual_questions.jsonl\"), \"w\") as f:\n",
    "    for ques in train_visual_questions:\n",
    "        f.write(json.dumps(ques) + \"\\n\")\n",
    "\n",
    "with open(os.path.join(NEW_BASE_DIR,  \"test_visual_questions.jsonl\"), \"w\") as f:\n",
    "    for ques in test_visual_questions:\n",
    "        f.write(json.dumps(ques) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exclusive_questions = [qid for qid in train_implicit_questions if qid['table_context'] in train_exclusive_tables]\n",
    "train_exclusive_questions += [qid for qid in train_explicit_questions if qid['table_context'] in train_exclusive_tables]\n",
    "train_exclusive_questions += [qid for qid in train_answer_questions if qid['table_context'] in train_exclusive_tables]\n",
    "\n",
    "with open(os.path.join(BASE_DIR, \"experiment_ready_dataset\", \"train_exclusive_questions.jsonl\"), \"w\") as f:\n",
    "    for ques in train_exclusive_questions:\n",
    "        f.write(json.dumps(ques) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_exclusive_questions))\n",
    "print(len(train_explicit_questions) + len(train_implicit_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_exclusive_tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_explicit_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
